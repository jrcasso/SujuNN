{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import cos, sin, pi\n",
    "from numpy.random import randint as r_int\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten,Dense,Dropout, GaussianNoise, GaussianDropout, LeakyReLU\n",
    "\n",
    "\n",
    "from PIL import Image as IM, ImageDraw as ID, ImageFilter as IF\n",
    "\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the Transformation Matrix for a Point\n",
    "#   coord: The (x,y,z) point to transform\n",
    "#   angle: The (a,b,c) angle to transform by\n",
    "def shear_trans(coord=(0,0,0),angle=(0,0,0)):\n",
    "    rot_x = np.array([[1,0,0],\n",
    "                      [0,cos(angle[0]), sin(angle[0])],\n",
    "                      [0,-sin(angle[0]),cos(angle[0])]],\n",
    "                    dtype='float32')\n",
    "    rot_y = np.array([[cos(angle[1]), 0, sin(angle[1])],\n",
    "                      [0, 1, 0],\n",
    "                      [-sin(angle[1]), 0, cos(angle[1])]],\n",
    "                    dtype='float32')\n",
    "    rot_z = np.array([[cos(angle[2]), -sin(angle[2]), 0],\n",
    "                      [sin(angle[2]), cos(angle[2]), 0],\n",
    "                      [0, 0, 1]],\n",
    "                    dtype='float32')\n",
    "\n",
    "    return np.dot(rot_x, rot_y, rot_z)\n",
    "\n",
    "# Generates Points for Polygons of Specified Features\n",
    "#   sides: Number of sides of polygon [default:3]\n",
    "#   coord: Center of the polygon  \n",
    "#   angle: Angle to rotate about center\n",
    "#   scale: Value to magnify the polygon\n",
    "#   shear: 3d Rotation to apply to polygon\n",
    "def poly_gen(sides = 3,coord = (0,0), angle = 0, scale = 1, shear = (0,0,0)):\n",
    "    p,x,y = [], *coord\n",
    "    \n",
    "    #Loop Through and Create All Verticies\n",
    "    for s in range(sides):\n",
    "        p.append( ( cos(s * 2 * pi / sides + angle) + x, sin(s * 2 * pi / sides + angle) + y))\n",
    "        \n",
    "    # Perform Shear Transform\n",
    "    p = map(lambda q: np.dot(shear_trans((0,0,0), shear), np.array([*q,0]).T), p)\n",
    "    p = list(map(lambda q: tuple(scale * (1 +  q.T[:-1] + np.array([x,y]))), p))\n",
    "    \n",
    "    return p\n",
    "\n",
    "# Generates Data Set of Polygons\n",
    "#   size: Number of Polygons to generate/Data Set Size\n",
    "#   side_range: Range of sides\n",
    "#   dim: Dimensions of the image\n",
    "#   color: Color of the polygon\n",
    "#   filled: Wether or not to fill in the polygon\n",
    "#   output_dir: Whether or not to save images & where to save them\n",
    "#   seed: Seed for numpy.random\n",
    "def gen_poly_data(size = 1,side_range=(3,10), dim = (100,100), color=0, filled=True, blurred=False, output_dir = None, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    data = {'x':[],'y':[],'img':[]}\n",
    "    few = 20\n",
    "    # Generate Random Shapes\n",
    "    for i in range(size):\n",
    "        img = IM.new('L', dim,\"#ffffff\")\n",
    "        draw = ID.Draw(img) \n",
    "        center = (1,1)#np.random.rand(2) * 3\n",
    "        scale = np.random.randint(np.min(dim)/8, np.min(dim)/4)\n",
    "        fill_color = color if filled else None\n",
    "        num_sides = r_int(*side_range)\n",
    "\n",
    "        draw.polygon(poly_gen(sides = num_sides,\n",
    "                             coord = center,\n",
    "                             angle = pi * np.random.rand(),\n",
    "                             scale = scale,\n",
    "                             shear = pi / 2 * np.random.rand(3) - pi/4),\n",
    "                     fill = fill_color, outline = color)\n",
    "        \n",
    "        # Blur Image True\n",
    "        if blurred:\n",
    "            img = img.filter(IF.BLUR)\n",
    "        \n",
    "        data['img'].append(img)\n",
    "        \n",
    "        # Save Image to output folder if given\n",
    "        if output_dir:\n",
    "            img.save(os.path.join(output_dir,'img_{}_class_{}.jpg'.format(num_sides,i)))\n",
    "        \n",
    "        data['x'].append(np.array(img,dtype='float32').reshape(200,200,1)/255)\n",
    "        \n",
    "        # One Hot Encode Label\n",
    "        one_hot = np.zeros(side_range[1] - side_range[0])\n",
    "        one_hot[num_sides - side_range[0]] = 1\n",
    "        data['y'].append(one_hot.T)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (4, 4), input_shape = (200, 200,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    # model.add(GaussianDropout(0.15))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu'))\n",
    "    # model.add(GaussianNoise(1))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 64, activation = 'sigmoid'))\n",
    "    model.add(Dense(units = 22, activation = 'softmax'))\n",
    "    model.add(Dense(units = 7, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 14:38:39.308582 16784 deprecation.py:506] From c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 197, 197, 64)      1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 95, 95, 16)        16400     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 35344)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2262080   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                1430      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 161       \n",
      "=================================================================\n",
      "Total params: 2,281,159\n",
      "Trainable params: 2,281,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 197, 197, 64)      1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 95, 95, 16)        16400     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 35344)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2262080   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 22)                1430      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 161       \n",
      "=================================================================\n",
      "Total params: 2,281,159\n",
      "Trainable params: 2,281,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_size, test_size = 5000, 500# 10000, 500\n",
    "train_set = gen_poly_data(train_size,side_range=(3,10), dim = (200,200), color=0, filled=True, blurred=False, output_dir = None, seed = 0)\n",
    "test_set = gen_poly_data(test_size,side_range=(3,10), dim = (200,200), color=0, filled=True, blurred=False, output_dir = None, seed = 1)\n",
    "\n",
    "\n",
    "model1,model2 = init_model(),init_model()\n",
    "epochs1, epochs2 = 8,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "4500/4500 [==============================] - 292s 65ms/sample - loss: 0.2176 - acc: 0.1478 - val_loss: 0.2001 - val_acc: 0.1440\n",
      "Epoch 2/8\n",
      "4500/4500 [==============================] - 2756s 612ms/sample - loss: 0.1906 - acc: 0.1411 - val_loss: 0.1807 - val_acc: 0.1440\n",
      "Epoch 3/8\n",
      "4500/4500 [==============================] - 288s 64ms/sample - loss: 0.1708 - acc: 0.1378 - val_loss: 0.1603 - val_acc: 0.1560\n",
      "Epoch 4/8\n",
      "4500/4500 [==============================] - 281s 62ms/sample - loss: 0.1530 - acc: 0.1529 - val_loss: 0.1475 - val_acc: 0.1560\n",
      "Epoch 5/8\n",
      "4500/4500 [==============================] - 276s 61ms/sample - loss: 0.1433 - acc: 0.1529 - val_loss: 0.1401 - val_acc: 0.1560\n",
      "Epoch 6/8\n",
      "4500/4500 [==============================] - 283s 63ms/sample - loss: 0.1374 - acc: 0.1529 - val_loss: 0.1353 - val_acc: 0.1560\n",
      "Epoch 7/8\n",
      "4500/4500 [==============================] - 298s 66ms/sample - loss: 0.1334 - acc: 0.1529 - val_loss: 0.1320 - val_acc: 0.1560\n",
      "Epoch 8/8\n",
      "4500/4500 [==============================] - 284s 63ms/sample - loss: 0.1306 - acc: 0.1529 - val_loss: 0.1296 - val_acc: 0.1560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac06f57400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(optimizer = tf.train.AdamOptimizer(), loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "model1.fit(np.array(train_set['x']), np.array(train_set['y']), batch_size = 64, epochs = epochs1, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 15:58:02.917703 16784 deprecation.py:323] From c:\\users\\jaures\\workspace\\sujunn\\env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "4500/4500 [==============================] - 291s 65ms/sample - loss: 1.9485 - acc: 0.1376 - categorical_accuracy: 0.1376 - val_loss: 1.9463 - val_acc: 0.1440 - val_categorical_accuracy: 0.1440\n",
      "Epoch 2/8\n",
      "4500/4500 [==============================] - 290s 64ms/sample - loss: 1.9462 - acc: 0.1489 - categorical_accuracy: 0.1489 - val_loss: 1.9453 - val_acc: 0.1560 - val_categorical_accuracy: 0.1560\n",
      "Epoch 3/8\n",
      "4500/4500 [==============================] - 296s 66ms/sample - loss: 1.9458 - acc: 0.1529 - categorical_accuracy: 0.1529 - val_loss: 1.9451 - val_acc: 0.1560 - val_categorical_accuracy: 0.1560\n",
      "Epoch 4/8\n",
      "4500/4500 [==============================] - 302s 67ms/sample - loss: 1.9459 - acc: 0.1529 - categorical_accuracy: 0.1529 - val_loss: 1.9450 - val_acc: 0.1560 - val_categorical_accuracy: 0.1560\n",
      "Epoch 5/8\n",
      "2112/4500 [=============>................] - ETA: 2:32 - loss: 1.9460 - acc: 0.1501 - categorical_accuracy: 0.1501"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer = tf.train.AdamOptimizer(), loss = 'categorical_crossentropy', metrics=['accuracy', 'categorical_accuracy'])\n",
    "model2.fit(np.array(train_set['x']), np.array(train_set['y']), batch_size = 32, epochs = epochs2, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Out[5].history['acc'])\n",
    "plt.plot(Out[5].history['loss'])\n",
    "plt.plot(Out[5].history['val_acc'])\n",
    "plt.plot(Out[5].history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Out[6].history['acc'])\n",
    "plt.plot(Out[6].history['loss'])\n",
    "plt.plot(Out[6].history['categorical_accuracy'])\n",
    "plt.plot(Out[6].history['val_acc'])\n",
    "plt.plot(Out[6].history['val_loss'])\n",
    "plt.plot(Out[6].history['val_categorical_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(test_size):\n",
    "    print('Checking Guess #{}:'.format(i),end='\\n\\t')\n",
    "    p = model1.predict(test_set['x'][i].reshape(1,200,200,1))\n",
    "    if np.argmax(p) == np.argmax(test_set['y'][i]):\n",
    "        print('[\\] - Match!')\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        print('[X] - Miss')        \n",
    "        display(test_set['img'][i])\n",
    "    print('Sides:\\n\\tGuess:{}\\n\\tActual:{}'.format( 3 + np.argmax(p), 3 + np.argmax(test_set['y'][i])),'\\n')\n",
    "\n",
    "print('Results: {}%'.format(correct/test_size * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(test_size):\n",
    "    print('Checking Guess #{}:'.format(i),end='\\n\\t')\n",
    "    p = model2.predict(test_set['x'][i].reshape(1,200,200,1))\n",
    "    if np.argmax(p) == np.argmax(test_set['y'][i]):\n",
    "        print('[\\] - Match!')\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        print('[X] - Miss')        \n",
    "        display(test_set['img'][i])\n",
    "    print('Sides:\\n\\tGuess:{}\\n\\tActual:{}'.format( 3 + np.argmax(p), 3 + np.argmax(test_set['y'][i])),'\\n')\n",
    "\n",
    "print('Results: {}%'.format(correct/test_size * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
