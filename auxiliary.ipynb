{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "\n",
    "from numpy import cos, sin, pi\n",
    "from numpy.random import randint as r_int\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten,Dense,Dropout, GaussianNoise, GaussianDropout, LeakyReLU\n",
    "\n",
    "from PIL import Image as IM, ImageDraw as ID, ImageFilter as IF\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the Transformation Matrix for a Point\n",
    "#   coord: The (x,y,z) point to transform\n",
    "#   angle: The (a,b,c) angle to transform by\n",
    "def shear_trans(coord=(0,0,0),angle=(0,0,0)):\n",
    "    rot_x = np.array([[1,0,0],\n",
    "                      [0,cos(angle[0]), sin(angle[0])],\n",
    "                      [0,-sin(angle[0]),cos(angle[0])]],\n",
    "                    dtype='float32')\n",
    "    rot_y = np.array([[cos(angle[1]), 0, sin(angle[1])],\n",
    "                      [0, 1, 0],\n",
    "                      [-sin(angle[1]), 0, cos(angle[1])]],\n",
    "                    dtype='float32')\n",
    "    rot_z = np.array([[cos(angle[2]), -sin(angle[2]), 0],\n",
    "                      [sin(angle[2]), cos(angle[2]), 0],\n",
    "                      [0, 0, 1]],\n",
    "                    dtype='float32')\n",
    "\n",
    "    return np.dot(rot_x, rot_y, rot_z)\n",
    "\n",
    "# Generates Points for Polygons of Specified Features\n",
    "#   sides: Number of sides of polygon [default:3]\n",
    "#   coord: Center of the polygon  \n",
    "#   angle: Angle to rotate about center\n",
    "#   scale: Value to magnify the polygon\n",
    "#   shear: 3d Rotation to apply to polygon\n",
    "def poly_gen(sides = 3,coord = (0,0), angle = 0, scale = 1, shear = (0,0,0)):\n",
    "    p,x,y = [], *coord\n",
    "    \n",
    "    #Loop Through and Create All Verticies\n",
    "    for s in range(sides):\n",
    "        p.append( ( cos(s * 2 * pi / sides + angle) + x, sin(s * 2 * pi / sides + angle) + y))\n",
    "        \n",
    "    # Perform Shear Transform\n",
    "    p = map(lambda q: np.dot(shear_trans((0,0,0), shear), np.array([*q,0]).T), p)\n",
    "    p = list(map(lambda q: tuple(scale * (1 +  q.T[:-1] + np.array([x,y]))), p))\n",
    "    \n",
    "    return p\n",
    "\n",
    "# Generates Data Set of Polygons\n",
    "#   size: Number of Polygons to generate/Data Set Size\n",
    "#   side_range: Range of sides\n",
    "#   dim: Dimensions of the image\n",
    "#   color: Color of the polygon\n",
    "#   filled: Wether or not to fill in the polygon\n",
    "#   output_dir: Whether or not to save images & where to save them\n",
    "#   seed: Seed for numpy.random\n",
    "def gen_poly_data(size = 1,side_range=(3,10), dim = (100,100), color=0, filled=True, blurred=False, output_dir = None, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    data = {'x':[],'y':[],'img':[]}\n",
    "    few = 20\n",
    "    # Generate Random Shapes\n",
    "    for i in range(size):\n",
    "        img = IM.new('L', dim,\"#ffffff\")\n",
    "        draw = ID.Draw(img) \n",
    "        center = (1,1)#np.random.rand(2) * 3\n",
    "        scale = np.random.randint(np.min(dim)/8, np.min(dim)/4)\n",
    "        fill_color = color if filled else None\n",
    "        num_sides = r_int(*side_range)\n",
    "\n",
    "        draw.polygon(poly_gen(sides = num_sides,\n",
    "                             coord = center,\n",
    "                             angle = pi * np.random.rand(),\n",
    "                             scale = scale,\n",
    "                             shear = pi / 2 * np.random.rand(3) - pi/4),\n",
    "                     fill = fill_color, outline = color)\n",
    "        \n",
    "        # Blur Image True\n",
    "        if blurred:\n",
    "            img = img.filter(IF.BLUR)\n",
    "        \n",
    "        data['img'].append(img)\n",
    "        \n",
    "        # Save Image to output folder if given\n",
    "        if output_dir:\n",
    "            img.save(os.path.join(output_dir,'img_{}_class_{}.jpg'.format(num_sides,i)))\n",
    "        \n",
    "        data['x'].append(np.array(img,dtype='float32').reshape(200,200,1)/255)\n",
    "        \n",
    "        # One Hot Encode Label\n",
    "        one_hot = np.zeros(side_range[1] - side_range[0])\n",
    "        one_hot[num_sides - side_range[0]] = 1\n",
    "        data['y'].append(one_hot.T)\n",
    "        \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (4, 4), input_shape = (200, 200,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    # model.add(GaussianDropout(0.15))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu'))\n",
    "    # model.add(GaussianNoise(1))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 64, activation = 'sigmoid'))\n",
    "    model.add(Dense(units = 22, activation = 'softmax'))\n",
    "    model.add(Dense(units = 7, activation = 'sigmoid'))\n",
    "    \n",
    "#     model.add(Conv2D(64, (4, 4), input_shape = (200, 200, 1), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size = (8, 8)))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(units = 64, activation = 'sigmoid'))\n",
    "#     model.add(Dense(units = 4, activation = 'sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size = 5000, 500# 10000, 500\n",
    "train_set = gen_poly_data(train_size,side_range=(3,10), dim = (200,200), color=0, filled=True, blurred=False, output_dir = None, seed = 0)\n",
    "test_set = gen_poly_data(test_size,side_range=(3,10), dim = (200,200), color=0, filled=True, blurred=False, output_dir = None, seed = 1)\n",
    "\n",
    "hasher = hashlib.md5()\n",
    "with open('auxiliary.ipynb', 'rb') as this_file:\n",
    "    hasher.update(this_file.read())\n",
    "this_hash = str(hasher.hexdigest())[:8]\n",
    "\n",
    "epochs1, epochs2 = 8,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 197, 197, 64)      1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 95, 95, 16)        16400     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 35344)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2262080   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 22)                1430      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 161       \n",
      "=================================================================\n",
      "Total params: 2,281,159\n",
      "Trainable params: 2,281,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "900/900 [==============================] - 53s 59ms/step - loss: 0.2194 - acc: 0.1533 - val_loss: 0.2111 - val_acc: 0.2100\n",
      "Epoch 2/2\n",
      "900/900 [==============================] - 53s 59ms/step - loss: 0.2088 - acc: 0.1467 - val_loss: 0.2058 - val_acc: 0.2100\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('mean_squared_model-' + this_hash + '.h5', 'r') as fh:\n",
    "        model1 = keras.models.load_model('mean_squared_model-' + this_hash + '.h5')\n",
    "except FileNotFoundError:\n",
    "    model1 = init_model()\n",
    "    model1.compile(optimizer = tf.train.AdamOptimizer(), loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "    model1.fit(np.array(train_set['x']), np.array(train_set['y']), batch_size = 64, epochs = epochs1, validation_split=0.1)\n",
    "    model1.save('mean_squared_model-' + this_hash + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 197, 197, 64)      1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 95, 95, 16)        16400     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 35344)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2262080   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 22)                1430      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 161       \n",
      "=================================================================\n",
      "Total params: 2,281,159\n",
      "Trainable params: 2,281,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "900/900 [==============================] - 54s 60ms/step - loss: 1.9497 - acc: 0.1511 - categorical_accuracy: 0.1511 - val_loss: 1.9525 - val_acc: 0.1300 - val_categorical_accuracy: 0.1300\n",
      "Epoch 2/2\n",
      "900/900 [==============================] - 55s 61ms/step - loss: 1.9470 - acc: 0.1556 - categorical_accuracy: 0.1556 - val_loss: 1.9512 - val_acc: 0.1300 - val_categorical_accuracy: 0.1300\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('cross_entropy_model-' + this_hash + '.h5', 'r') as fh:\n",
    "        model2 = keras.models.load_model('cross_entropy_model-' + this_hash + '.h5')\n",
    "except FileNotFoundError:\n",
    "    model2 = init_model()\n",
    "    model2.compile(optimizer = tf.train.AdamOptimizer(), loss = 'categorical_crossentropy', metrics=['accuracy', 'categorical_accuracy'])\n",
    "    model2.fit(np.array(train_set['x']), np.array(train_set['y']), batch_size = 32, epochs = epochs2, validation_split=0.1)\n",
    "    model2.save('cross_entropy_model-' + this_hash + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-bdce6d57e1ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "plt.plot(Out[5].history['acc'])\n",
    "plt.plot(Out[5].history['loss'])\n",
    "plt.plot(Out[5].history['val_acc'])\n",
    "plt.plot(Out[5].history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Out[6].history['acc'])\n",
    "plt.plot(Out[6].history['loss'])\n",
    "plt.plot(Out[6].history['categorical_accuracy'])\n",
    "plt.plot(Out[6].history['val_acc'])\n",
    "plt.plot(Out[6].history['val_loss'])\n",
    "plt.plot(Out[6].history['val_categorical_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(test_size):\n",
    "    print('Checking Guess #{}:'.format(i),end='\\n\\t')\n",
    "    p = model1.predict(test_set['x'][i].reshape(1,200,200,1))\n",
    "    if np.argmax(p) == np.argmax(test_set['y'][i]):\n",
    "        print('[\\] - Match!')\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        print('[X] - Miss')        \n",
    "        display(test_set['img'][i])\n",
    "    print('Sides:\\n\\tGuess:{}\\n\\tActual:{}'.format( 3 + np.argmax(p), 3 + np.argmax(test_set['y'][i])),'\\n')\n",
    "\n",
    "print('Results: {}%'.format(correct/test_size * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(test_size):\n",
    "    print('Checking Guess #{}:'.format(i),end='\\n\\t')\n",
    "    p = model2.predict(test_set['x'][i].reshape(1,200,200,1))\n",
    "    if np.argmax(p) == np.argmax(test_set['y'][i]):\n",
    "        print('[\\] - Match!')\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        print('[X] - Miss')        \n",
    "        display(test_set['img'][i])\n",
    "    print('Sides:\\n\\tGuess:{}\\n\\tActual:{}'.format( 3 + np.argmax(p), 3 + np.argmax(test_set['y'][i])),'\\n')\n",
    "\n",
    "print('Results: {}%'.format(correct/test_size * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir(gen_poly_data)\n",
    "# gen_poly_data.__getattribute__()\n",
    "gen_poly_data.__defaults__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
